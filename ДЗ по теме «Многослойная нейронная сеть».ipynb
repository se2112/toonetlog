{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d10e14-5a39-4673-b0ff-801ac8154a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "##–î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ –ø–æ —Ç–µ–º–µ ¬´–ú–Ω–æ–≥–æ—Å–ª–æ–π–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å¬ª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c75050-3e71-430c-bf24-c6b1b2219d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "–ó–∞–¥–∞–Ω–∏–µ\n",
    "–ü–æ—Å—Ç—Ä–æ–π—Ç–µ –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã—Ö —Å–ª–æ—ë–≤ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ Fashion MNIST –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ torchvision (datasets).\n",
    "–ü–æ–ª—É—á–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ –Ω–µ –Ω–∏–∂–µ 88%\n",
    "\n",
    "–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é –∑–∞–¥–∞–Ω–∏—è\n",
    "\n",
    "1. –°–∫–∞—á–∞–π—Ç–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é –∏ —Ç–µ—Å—Ç–æ–≤–æ—é —á–∞—Å—Ç—å –¥–∞—Ç–∞—Å–µ—Ç–∞ Fashion MNIST\n",
    "2. –ü–æ—Å—Ç—Ä–æ–π—Ç–µ –º–æ–¥–µ–ª—å, –≤—ã–±—Ä–∞–≤ —Å—Ç–∞—Ä—Ç–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É\n",
    "3. –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –∏ —Å–≤–µ—Ä—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π —á–∞—Å—Ç–∏ —Å –∑–∞–¥–∞–Ω–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º\n",
    "4. –ò–∑–º–µ–Ω—è–π—Ç–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏ –ø–æ–∫–∞ –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π —á–∞—Å—Ç–∏ –Ω–µ –±—É–¥–µ—Ç –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞. \n",
    "–í–∞—Ä–∏–∞—Ü–∏–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —á–µ—Ä–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ—ë–≤, –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –Ω–µ–π—Ä–æ–Ω–æ–≤ –≤ —Å–ª–æ—è—Ö –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏. \n",
    "–ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eeaa29-16b6-4b6f-83de-53987499e537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa0914be-e18d-4a4a-98c0-b603d74b9abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1106986-0365-4f1f-a75f-1d31c0d87fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. –°–∫–∞—á–∞–π—Ç–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é –∏ —Ç–µ—Å—Ç–æ–≤–æ—é —á–∞—Å—Ç—å –¥–∞—Ç–∞—Å–µ—Ç–∞ Fashion MNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61c1fed9-8532-4442-99e2-b0eb76b90e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò—Å–ø–æ–ª—å–∑—É–µ–º : cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ–º : {device}\")\n",
    "\n",
    "# –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö FashionMNIST\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d0217c-c369-4aa9-9f78-b49f726d5b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. –ü–æ—Å—Ç—Ä–æ–π—Ç–µ –º–æ–¥–µ–ª—å, –≤—ã–±—Ä–∞–≤ —Å—Ç–∞—Ä—Ç–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09933937-6a55-49ca-82e3-7292eda823fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),         # –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º 28x28 –∫–∞—Ä—Ç–∏–Ω–∫—É –≤ –≤–µ–∫—Ç–æ—Ä 784\n",
    "    nn.Linear(784, 128),  # –ü–µ—Ä–≤—ã–π —Å–∫—Ä—ã—Ç—ã–π —Å–ª–æ–π (128 –Ω–µ–π—Ä–æ–Ω–æ–≤)\n",
    "    nn.ReLU(),           # –ê–∫—Ç–∏–≤–∞—Ü–∏—è ReLU\n",
    "    nn.Linear(128, 10)    # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π \n",
    ")\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1755ede5-bc17-492e-80f4-9ff9918acdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    " # –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60e4ef5a-ade5-4c03-9fa2-d30dfbe52fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "loss = nn.CrossEntropyLoss()\n",
    "trainer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbdb8255-8501-4eff-a501-65def4d7cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    for ep in range(EPOCHS):\n",
    "        train_iters, train_passed = 0, 0\n",
    "        train_loss, train_acc = 0., 0.\n",
    "        start = time.time()\n",
    "        \n",
    "        model.train()\n",
    "        for X, y in train:\n",
    "            trainer.zero_grad()\n",
    "            y_pred = model(X.view(-1, 28*28))  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É –≤ –≤–µ–∫—Ç–æ—Ä 784 —ç–ª–µ–º–µ–Ω—Ç–æ–≤\n",
    "            l = loss(y_pred, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            \n",
    "            train_loss += l.item()\n",
    "            train_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            train_iters += 1\n",
    "            train_passed += len(X)\n",
    "        \n",
    "        test_iters, test_passed = 0, 0\n",
    "        test_loss, test_acc = 0., 0.\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X, y in test:\n",
    "                y_pred = model(X.view(-1, 28*28))\n",
    "                l = loss(y_pred, y)\n",
    "                \n",
    "                test_loss += l.item()\n",
    "                test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "                test_iters += 1\n",
    "                test_passed += len(X)\n",
    "        \n",
    "        print(f\"ep: {ep}, time: {time.time() - start:.3f}, \"\n",
    "              f\"train_loss: {train_loss / train_iters:.4f}, train_acc: {train_acc / train_passed:.4f}, \"\n",
    "              f\"test_loss: {test_loss / test_iters:.4f}, test_acc: {test_acc / test_passed:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00aa5d8c-e81e-4eaf-aa22-cf5f83a9c711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, time: 1.814, train_loss: 0.5579, train_acc: 0.8073, test_loss: 0.4851, test_acc: 0.8251\n",
      "ep: 1, time: 2.095, train_loss: 0.4066, train_acc: 0.8557, test_loss: 0.4234, test_acc: 0.8499\n",
      "ep: 2, time: 2.073, train_loss: 0.3681, train_acc: 0.8691, test_loss: 0.3963, test_acc: 0.8591\n",
      "ep: 3, time: 5.650, train_loss: 0.3415, train_acc: 0.8770, test_loss: 0.3685, test_acc: 0.8678\n",
      "ep: 4, time: 3.239, train_loss: 0.3204, train_acc: 0.8845, test_loss: 0.3601, test_acc: 0.8717\n",
      "ep: 5, time: 2.264, train_loss: 0.3037, train_acc: 0.8893, test_loss: 0.3381, test_acc: 0.8810\n",
      "ep: 6, time: 2.137, train_loss: 0.2923, train_acc: 0.8932, test_loss: 0.3454, test_acc: 0.8777\n",
      "ep: 7, time: 2.097, train_loss: 0.2790, train_acc: 0.8972, test_loss: 0.3511, test_acc: 0.8737\n",
      "ep: 8, time: 5.702, train_loss: 0.2712, train_acc: 0.8999, test_loss: 0.3313, test_acc: 0.8816\n",
      "ep: 9, time: 6.014, train_loss: 0.2622, train_acc: 0.9027, test_loss: 0.3268, test_acc: 0.8851\n"
     ]
    }
   ],
   "source": [
    "train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fa148d-f35a-4d50-98fb-3fb1fa7553d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_acc: 0.8851 –Ω–∞  \n",
    "#BATCH_SIZE = 64\n",
    "#EPOCHS = 10\n",
    "#LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2431b561-5c50-464e-b418-70ba9321d38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò—Å–ø–æ–ª—å–∑—É–µ–º : cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ–º : {device}\")\n",
    "\n",
    "# –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö FashionMNIST\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169118d4-aab6-46eb-82c3-2971d1a00655",
   "metadata": {},
   "outputs": [],
   "source": [
    "BatchNorm1d ‚Äî —É—Å–∫–æ—Ä—è–µ—Ç –æ–±—É—á–µ–Ω–∏–µ\n",
    "Dropout ‚Äî –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ\n",
    "–ë–æ–ª—å—à–µ –Ω–µ–π—Ä–æ–Ω–æ–≤ –≤ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "25faa998-d535-47f5-973a-b2bd14dfae31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=784, out_features=2048, bias=True)\n",
      "  (2): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (3): LeakyReLU(negative_slope=0.1)\n",
      "  (4): Dropout(p=0.4, inplace=False)\n",
      "  (5): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (6): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): LeakyReLU(negative_slope=0.1)\n",
      "  (8): Dropout(p=0.4, inplace=False)\n",
      "  (9): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (10): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (11): LeakyReLU(negative_slope=0.1)\n",
      "  (12): Dropout(p=0.3, inplace=False)\n",
      "  (13): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (14): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (15): LeakyReLU(negative_slope=0.1)\n",
      "  (16): Dropout(p=0.3, inplace=False)\n",
      "  (17): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (18): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (19): SELU()\n",
      "  (20): Dropout(p=0.2, inplace=False)\n",
      "  (21): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (22): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (23): SELU()\n",
      "  (24): Dropout(p=0.2, inplace=False)\n",
      "  (25): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# –£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è FashionMNIST\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "\n",
    "    nn.Linear(784, 2048),\n",
    "    nn.BatchNorm1d(2048),\n",
    "    nn.LeakyReLU(0.1),  # –£–ª—É—á—à–µ–Ω–Ω–∞—è –∞–∫—Ç–∏–≤–∞—Ü–∏—è\n",
    "    nn.Dropout(0.4),  # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π dropout\n",
    "\n",
    "    nn.Linear(2048, 1024),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    nn.LeakyReLU(0.1),\n",
    "    nn.Dropout(0.4),\n",
    "\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.LeakyReLU(0.1),\n",
    "    nn.Dropout(0.3),\n",
    "\n",
    "    nn.Linear(512, 256),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.LeakyReLU(0.1),\n",
    "    nn.Dropout(0.3),\n",
    "\n",
    "    nn.Linear(256, 128),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.SELU(),  # SELU –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è\n",
    "    nn.Dropout(0.2),  # –ß—É—Ç—å –º–µ–Ω—å—à–µ dropout\n",
    "\n",
    "    nn.Linear(128, 64),\n",
    "    nn.BatchNorm1d(64),\n",
    "    nn.SELU(),\n",
    "    nn.Dropout(0.2),\n",
    "\n",
    "    nn.Linear(64, 10)  # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π \n",
    ")\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e373b22d-551d-4e19-84ed-e44f11259fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–æ–±–∞–≤–∏–ª switch_to_sgd() ‚Äî –æ–Ω–∞ –∑–∞–º–µ–Ω—è–µ—Ç Adam –Ω–∞ SGD –ø–æ—Å–ª–µ 10 —ç–ø–æ—Ö.\n",
    "# –í—ã–∑—ã–≤–∞–µ–º –µ—ë –≤ train_model() –ø–æ—Å–ª–µ 10-–π —ç–ø–æ—Ö–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ec161223-2d6c-4744-b750-e6d981b4795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# 1. –ù–∞—á–∏–Ω–∞–µ–º —Å Adam\n",
    "trainer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# 2. –§—É–Ω–∫—Ü–∏—è —Å–º–µ–Ω—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –ø–æ—Å–ª–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —ç–ø–æ—Ö\n",
    "def switch_to_sgd():\n",
    "    global trainer  # –ú–µ–Ω—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é\n",
    "    trainer = optim.SGD(model.parameters(), lr=LEARNING_RATE / 10, momentum=0.9, weight_decay=1e-4)\n",
    "    print(\"üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∏–ª–∏—Å—å –Ω–∞ SGD!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4b37ac00-7128-4977-839b-58702fd8ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "trainer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –Ω–∞ SGD\n",
    "def switch_to_sgd():\n",
    "    global trainer\n",
    "    trainer = optim.SGD(model.parameters(), lr=LEARNING_RATE / 10, momentum=0.9, weight_decay=1e-4)\n",
    "    print(\"üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∏–ª–∏—Å—å –Ω–∞ SGD!\")\n",
    "\n",
    "def train_model():\n",
    "    for ep in range(EPOCHS):\n",
    "        train_iters, train_passed = 0, 0\n",
    "        train_loss, train_acc = 0., 0.\n",
    "        start = time.time()\n",
    "        \n",
    "        model.train()\n",
    "        for X, y in train:\n",
    "            trainer.zero_grad()\n",
    "            y_pred = model(X.view(-1, 28*28))  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É –≤ –≤–µ–∫—Ç–æ—Ä 784 —ç–ª–µ–º–µ–Ω—Ç–æ–≤\n",
    "            l = loss(y_pred, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            \n",
    "            train_loss += l.item()\n",
    "            train_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            train_iters += 1\n",
    "            train_passed += len(X)\n",
    "        \n",
    "        test_iters, test_passed = 0, 0\n",
    "        test_loss, test_acc = 0., 0.\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X, y in test:\n",
    "                y_pred = model(X.view(-1, 28*28))\n",
    "                l = loss(y_pred, y)\n",
    "                \n",
    "                test_loss += l.item()\n",
    "                test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "                test_iters += 1\n",
    "                test_passed += len(X)\n",
    "        \n",
    "        print(f\"ep: {ep}, time: {time.time() - start:.3f}, \"\n",
    "              f\"train_loss: {train_loss / train_iters:.4f}, train_acc: {train_acc / train_passed:.4f}, \"\n",
    "              f\"test_loss: {test_loss / test_iters:.4f}, test_acc: {test_acc / test_passed:.4f}\")\n",
    "        \n",
    "        # –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ SGD –ø–æ—Å–ª–µ 10 —ç–ø–æ—Ö\n",
    "        if ep == 10:\n",
    "            switch_to_sgd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f65ee750-47fd-4c35-a488-9071b5fc0a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, time: 11.143, train_loss: 0.3018, train_acc: 0.8922, test_loss: 0.3267, test_acc: 0.8816\n",
      "ep: 1, time: 11.067, train_loss: 0.2954, train_acc: 0.8930, test_loss: 0.3137, test_acc: 0.8858\n",
      "ep: 2, time: 11.761, train_loss: 0.2841, train_acc: 0.8974, test_loss: 0.3168, test_acc: 0.8856\n",
      "ep: 3, time: 10.877, train_loss: 0.2798, train_acc: 0.8984, test_loss: 0.3105, test_acc: 0.8884\n",
      "ep: 4, time: 10.799, train_loss: 0.2723, train_acc: 0.9012, test_loss: 0.3039, test_acc: 0.8900\n",
      "ep: 5, time: 10.766, train_loss: 0.2645, train_acc: 0.9039, test_loss: 0.3251, test_acc: 0.8795\n",
      "ep: 6, time: 10.854, train_loss: 0.2621, train_acc: 0.9046, test_loss: 0.3075, test_acc: 0.8862\n",
      "ep: 7, time: 10.792, train_loss: 0.2518, train_acc: 0.9077, test_loss: 0.3044, test_acc: 0.8911\n",
      "ep: 8, time: 10.769, train_loss: 0.2488, train_acc: 0.9086, test_loss: 0.3008, test_acc: 0.8934\n",
      "ep: 9, time: 10.798, train_loss: 0.2392, train_acc: 0.9124, test_loss: 0.2893, test_acc: 0.8981\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c871f4-41db-4b67-a79f-a8bdda126b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss –ø–∞–¥–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ –∏ –Ω–∞ train –∏ –Ω–∞ test —á—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç —á—Ç–æ –º–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è, \n",
    "# –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—Å—è –Ω–∞ 10 —ç–ø–æ—Ö–∞—Ö , –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –Ω–µ—Ç test_acc: 0.8981"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332ed19f-716b-403f-b6ac-bfe7d1ad2871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
