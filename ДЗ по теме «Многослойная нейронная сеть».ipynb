{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d10e14-5a39-4673-b0ff-801ac8154a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Домашнее задание по теме «Многослойная нейронная сеть»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c75050-3e71-430c-bf24-c6b1b2219d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Задание\n",
    "Постройте модель на основе полносвязных слоёв для классификации Fashion MNIST из библиотеки torchvision (datasets).\n",
    "Получите качество на тестовой выборке не ниже 88%\n",
    "\n",
    "Инструкция по выполнению задания\n",
    "\n",
    "1. Скачайте тренировочную и тестовою часть датасета Fashion MNIST\n",
    "2. Постройте модель, выбрав стартовую архитектуру\n",
    "3. Обучите модель и сверьте качество на тестовой части с заданным порогом\n",
    "4. Изменяйте архитектуру модели пока качество на тестовой части не будет выше порога. \n",
    "Вариации архитектуры можно реализовать через изменение количества слоёв, количества нейронов в слоях и использование регуляризации. \n",
    "Можно использовать различные оптимизаторы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eeaa29-16b6-4b6f-83de-53987499e537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa0914be-e18d-4a4a-98c0-b603d74b9abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1106986-0365-4f1f-a75f-1d31c0d87fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Скачайте тренировочную и тестовою часть датасета Fashion MNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61c1fed9-8532-4442-99e2-b0eb76b90e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используем : cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Используем : {device}\")\n",
    "\n",
    "# Гиперпараметры\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Загрузка данных FashionMNIST\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d0217c-c369-4aa9-9f78-b49f726d5b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Постройте модель, выбрав стартовую архитектуру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09933937-6a55-49ca-82e3-7292eda823fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),         # Превращаем 28x28 картинку в вектор 784\n",
    "    nn.Linear(784, 128),  # Первый скрытый слой (128 нейронов)\n",
    "    nn.ReLU(),           # Активация ReLU\n",
    "    nn.Linear(128, 10)    # Выходной слой \n",
    ")\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1755ede5-bc17-492e-80f4-9ff9918acdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Функция потерь и оптимизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60e4ef5a-ade5-4c03-9fa2-d30dfbe52fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "loss = nn.CrossEntropyLoss()\n",
    "trainer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbdb8255-8501-4eff-a501-65def4d7cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    for ep in range(EPOCHS):\n",
    "        train_iters, train_passed = 0, 0\n",
    "        train_loss, train_acc = 0., 0.\n",
    "        start = time.time()\n",
    "        \n",
    "        model.train()\n",
    "        for X, y in train:\n",
    "            trainer.zero_grad()\n",
    "            y_pred = model(X.view(-1, 28*28))  # Преобразуем картинку в вектор 784 элементов\n",
    "            l = loss(y_pred, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            \n",
    "            train_loss += l.item()\n",
    "            train_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            train_iters += 1\n",
    "            train_passed += len(X)\n",
    "        \n",
    "        test_iters, test_passed = 0, 0\n",
    "        test_loss, test_acc = 0., 0.\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X, y in test:\n",
    "                y_pred = model(X.view(-1, 28*28))\n",
    "                l = loss(y_pred, y)\n",
    "                \n",
    "                test_loss += l.item()\n",
    "                test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "                test_iters += 1\n",
    "                test_passed += len(X)\n",
    "        \n",
    "        print(f\"ep: {ep}, time: {time.time() - start:.3f}, \"\n",
    "              f\"train_loss: {train_loss / train_iters:.4f}, train_acc: {train_acc / train_passed:.4f}, \"\n",
    "              f\"test_loss: {test_loss / test_iters:.4f}, test_acc: {test_acc / test_passed:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00aa5d8c-e81e-4eaf-aa22-cf5f83a9c711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, time: 1.814, train_loss: 0.5579, train_acc: 0.8073, test_loss: 0.4851, test_acc: 0.8251\n",
      "ep: 1, time: 2.095, train_loss: 0.4066, train_acc: 0.8557, test_loss: 0.4234, test_acc: 0.8499\n",
      "ep: 2, time: 2.073, train_loss: 0.3681, train_acc: 0.8691, test_loss: 0.3963, test_acc: 0.8591\n",
      "ep: 3, time: 5.650, train_loss: 0.3415, train_acc: 0.8770, test_loss: 0.3685, test_acc: 0.8678\n",
      "ep: 4, time: 3.239, train_loss: 0.3204, train_acc: 0.8845, test_loss: 0.3601, test_acc: 0.8717\n",
      "ep: 5, time: 2.264, train_loss: 0.3037, train_acc: 0.8893, test_loss: 0.3381, test_acc: 0.8810\n",
      "ep: 6, time: 2.137, train_loss: 0.2923, train_acc: 0.8932, test_loss: 0.3454, test_acc: 0.8777\n",
      "ep: 7, time: 2.097, train_loss: 0.2790, train_acc: 0.8972, test_loss: 0.3511, test_acc: 0.8737\n",
      "ep: 8, time: 5.702, train_loss: 0.2712, train_acc: 0.8999, test_loss: 0.3313, test_acc: 0.8816\n",
      "ep: 9, time: 6.014, train_loss: 0.2622, train_acc: 0.9027, test_loss: 0.3268, test_acc: 0.8851\n"
     ]
    }
   ],
   "source": [
    "train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fa148d-f35a-4d50-98fb-3fb1fa7553d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_acc: 0.8851 на  \n",
    "#BATCH_SIZE = 64\n",
    "#EPOCHS = 10\n",
    "#LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2431b561-5c50-464e-b418-70ba9321d38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используем : cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Используем : {device}\")\n",
    "\n",
    "# Гиперпараметры\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Загрузка данных FashionMNIST\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169118d4-aab6-46eb-82c3-2971d1a00655",
   "metadata": {},
   "outputs": [],
   "source": [
    "BatchNorm1d — ускоряет обучение\n",
    "Dropout — предотвращает переобучение\n",
    "Больше нейронов в скрытых слоях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "25faa998-d535-47f5-973a-b2bd14dfae31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=784, out_features=2048, bias=True)\n",
      "  (2): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (3): LeakyReLU(negative_slope=0.1)\n",
      "  (4): Dropout(p=0.4, inplace=False)\n",
      "  (5): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (6): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): LeakyReLU(negative_slope=0.1)\n",
      "  (8): Dropout(p=0.4, inplace=False)\n",
      "  (9): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (10): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (11): LeakyReLU(negative_slope=0.1)\n",
      "  (12): Dropout(p=0.3, inplace=False)\n",
      "  (13): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (14): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (15): LeakyReLU(negative_slope=0.1)\n",
      "  (16): Dropout(p=0.3, inplace=False)\n",
      "  (17): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (18): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (19): SELU()\n",
      "  (20): Dropout(p=0.2, inplace=False)\n",
      "  (21): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (22): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (23): SELU()\n",
      "  (24): Dropout(p=0.2, inplace=False)\n",
      "  (25): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Улучшенная модель для FashionMNIST\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "\n",
    "    nn.Linear(784, 2048),\n",
    "    nn.BatchNorm1d(2048),\n",
    "    nn.LeakyReLU(0.1),  # Улучшенная активация\n",
    "    nn.Dropout(0.4),  # Увеличенный dropout\n",
    "\n",
    "    nn.Linear(2048, 1024),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    nn.LeakyReLU(0.1),\n",
    "    nn.Dropout(0.4),\n",
    "\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.LeakyReLU(0.1),\n",
    "    nn.Dropout(0.3),\n",
    "\n",
    "    nn.Linear(512, 256),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.LeakyReLU(0.1),\n",
    "    nn.Dropout(0.3),\n",
    "\n",
    "    nn.Linear(256, 128),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.SELU(),  # SELU для стабилизации обучения\n",
    "    nn.Dropout(0.2),  # Чуть меньше dropout\n",
    "\n",
    "    nn.Linear(128, 64),\n",
    "    nn.BatchNorm1d(64),\n",
    "    nn.SELU(),\n",
    "    nn.Dropout(0.2),\n",
    "\n",
    "    nn.Linear(64, 10)  # Выходной слой \n",
    ")\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e373b22d-551d-4e19-84ed-e44f11259fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавил switch_to_sgd() — она заменяет Adam на SGD после 10 эпох.\n",
    "# Вызываем её в train_model() после 10-й эпохи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ec161223-2d6c-4744-b750-e6d981b4795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# 1. Начинаем с Adam\n",
    "trainer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# 2. Функция смены оптимизатора после нескольких эпох\n",
    "def switch_to_sgd():\n",
    "    global trainer  # Меняем глобальную переменную\n",
    "    trainer = optim.SGD(model.parameters(), lr=LEARNING_RATE / 10, momentum=0.9, weight_decay=1e-4)\n",
    "    print(\"🔄 Переключились на SGD!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4b37ac00-7128-4977-839b-58702fd8ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "trainer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Функция переключения на SGD\n",
    "def switch_to_sgd():\n",
    "    global trainer\n",
    "    trainer = optim.SGD(model.parameters(), lr=LEARNING_RATE / 10, momentum=0.9, weight_decay=1e-4)\n",
    "    print(\"🔄 Переключились на SGD!\")\n",
    "\n",
    "def train_model():\n",
    "    for ep in range(EPOCHS):\n",
    "        train_iters, train_passed = 0, 0\n",
    "        train_loss, train_acc = 0., 0.\n",
    "        start = time.time()\n",
    "        \n",
    "        model.train()\n",
    "        for X, y in train:\n",
    "            trainer.zero_grad()\n",
    "            y_pred = model(X.view(-1, 28*28))  # Преобразуем картинку в вектор 784 элементов\n",
    "            l = loss(y_pred, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            \n",
    "            train_loss += l.item()\n",
    "            train_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            train_iters += 1\n",
    "            train_passed += len(X)\n",
    "        \n",
    "        test_iters, test_passed = 0, 0\n",
    "        test_loss, test_acc = 0., 0.\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X, y in test:\n",
    "                y_pred = model(X.view(-1, 28*28))\n",
    "                l = loss(y_pred, y)\n",
    "                \n",
    "                test_loss += l.item()\n",
    "                test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "                test_iters += 1\n",
    "                test_passed += len(X)\n",
    "        \n",
    "        print(f\"ep: {ep}, time: {time.time() - start:.3f}, \"\n",
    "              f\"train_loss: {train_loss / train_iters:.4f}, train_acc: {train_acc / train_passed:.4f}, \"\n",
    "              f\"test_loss: {test_loss / test_iters:.4f}, test_acc: {test_acc / test_passed:.4f}\")\n",
    "        \n",
    "        # Переключаемся на SGD после 10 эпох\n",
    "        if ep == 10:\n",
    "            switch_to_sgd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f65ee750-47fd-4c35-a488-9071b5fc0a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, time: 11.143, train_loss: 0.3018, train_acc: 0.8922, test_loss: 0.3267, test_acc: 0.8816\n",
      "ep: 1, time: 11.067, train_loss: 0.2954, train_acc: 0.8930, test_loss: 0.3137, test_acc: 0.8858\n",
      "ep: 2, time: 11.761, train_loss: 0.2841, train_acc: 0.8974, test_loss: 0.3168, test_acc: 0.8856\n",
      "ep: 3, time: 10.877, train_loss: 0.2798, train_acc: 0.8984, test_loss: 0.3105, test_acc: 0.8884\n",
      "ep: 4, time: 10.799, train_loss: 0.2723, train_acc: 0.9012, test_loss: 0.3039, test_acc: 0.8900\n",
      "ep: 5, time: 10.766, train_loss: 0.2645, train_acc: 0.9039, test_loss: 0.3251, test_acc: 0.8795\n",
      "ep: 6, time: 10.854, train_loss: 0.2621, train_acc: 0.9046, test_loss: 0.3075, test_acc: 0.8862\n",
      "ep: 7, time: 10.792, train_loss: 0.2518, train_acc: 0.9077, test_loss: 0.3044, test_acc: 0.8911\n",
      "ep: 8, time: 10.769, train_loss: 0.2488, train_acc: 0.9086, test_loss: 0.3008, test_acc: 0.8934\n",
      "ep: 9, time: 10.798, train_loss: 0.2392, train_acc: 0.9124, test_loss: 0.2893, test_acc: 0.8981\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c871f4-41db-4b67-a79f-a8bdda126b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss падает стабильно и на train и на test что говорит что модель обучается, \n",
    "# останавливаемсся на 10 эпохах , переобучения нет test_acc: 0.8981"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332ed19f-716b-403f-b6ac-bfe7d1ad2871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
# TODO: Проверить модель на других данных
